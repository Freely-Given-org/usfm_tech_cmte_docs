#!/usr/bin/env -S python3 -u

import argparse, zipfile, os, sys, itertools, re
from multiprocessing import Pool
from math import sqrt
import logging
import logging.config

def lognprint(s, q, level=logging.DEBUG):
    log.log(level, s)
    if not q:
        print(s, flush=True)

try:
    from usfmtc.sfmparser import UsfmParserBackend, parseusfm
except ImportError:
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'lib'))
    from usfmtc.sfmparser import UsfmParserBackend, parseusfm
from usfmtc.parser import NoParseError, Parser
from usfmtc.grammar import UsfmGrammarParser
from usfmtc.usxgrammar import usxenums
from usfmtc.usx import addesids, etCmp, cell_aligns, cleanup, partypes
import xml.etree.ElementTree as et
from lxml import etree

def proconezip(fpath, sfmp, log, relax, args):
    lognprint(f"{fpath}: started", args.quiet)
    try:
        zipf = zipfile.ZipFile(fpath)
    except (OSError, zipfile.BadZipFile) as e:
        lognprint(f"{fpath}: Skipped {e}", args.quiet, logging.INFO)
        return (fpath, None)
    try:
        fh = zipf.open("source/source.zip")
    except (KeyError, OSError) as e:
        zipf.close()
        lognprint(f"{fpath}: Skipped (no source) {e}", args.quiet, logging.INFO)
        return (fpath, None)
    try:
        szip = zipfile.ZipFile(fh)
    except zipfile.BadZipFile as e:
        lognprint(f"{fpath}: Skipped. Bad Zip file source/source.zip {e}", args.quiet, logging.INFO)
        return (fpath, None)
    results = []
    anyfailed = False
    if args.do in ("all", "usfm"):
        for f in szip.namelist():
            if f.lower().endswith('sfm'):
                m = re.match(r'(\d{2})', f)
                if m is None or not (0 < int(m.group(1)) < 68):
                    continue
            else:
                continue
            if args.verbose:
                lognprint(f"{fpath}/{f}", args.quiet)
            sfmfh = szip.open(f)
            result = None
            failed = False
            try:
                result = parseusfm(sfmfh, sfmp, timeout=args.timeout or 3600)
            except NoParseError as e:
                imsg = " {} at {} in {}".format(e.msg, e.state.pos, f).replace("\r", "\\r")
                results.append(imsg)
                lognprint(f"{fpath}/{f}: {imsg}", args.quiet)
                failed = True
            except TimeoutError:
                lognprint(f"{fpath}: Timed out", args.quiet, logging.INFO)
                results.append("Timed out")
                failed = True
            except UnicodeError:
                lognprint(f"{fpath}: Skipped. Encoding error, probably latin-1?", args.quiet, logging.INFO)
                results.append("Encoding error")
                failed = True
            if result is not None:
                xml = result.asEt()
                addesids(xml)
                cell_aligns(xml)
                cleanup(xml)
                etreexml = etree.fromstring(et.tostring(xml, encoding="utf-8", xml_declaration=True))
                if not relax.validate(etreexml):
                    xmsg = str(relax.error_log.last_error)
                    if failed:
                        results[-1] += " |xml> " + xmsg
                    else:
                        results.append(f"{fpath}/{f} |xml> {xmsg}")
                    lognprint(f"{fpath}/{f}: XML| {xmsg}", args.quiet, logging.INFO)
            anyfailed |= failed
            if failed and args.oneerror:
                break
        szip.close()
    if args.do in ("all", "usx"):
        usxjobs = [x for x in zipf.namelist() if x.startswith("release/USX_1/") and x.lower().endswith(".USX")]
        for ausx in usxjobs:
            with zipf.open(ausx) as xf:
                doc = etree.parse(xf)
                if not relax.valide(doc):
                    xmsg = str(relax.error_log.last_error)
                    err = f"{fpath}/{ausx} XML: {xmsg}"
                    results.append(err)
                    lognprint(err, args.quiet, logging.INFO)
                    anyfailed = True
                    if args.oneerror:
                        break
    zipf.close()
    lognprint("{}: {}".format(fpath, "Passed" if not anyfailed else "Failed"), args.quiet, logging.INFO)
    return (fpath, results)

def chunkjobs(jobs, nchunks):
    chunksize = len(jobs) // nchunks
    chunksize += 1 if len(jobs) % nchunks else 0
    tjobs = [j[0] for j in sorted(jobs, key=lambda x:(-x[1], x[0]))]
    dojobs = []
    for i in range(nchunks):
        if args.debug & 2 == 0:
            lj = [x for x in itertools.chain(*itertools.zip_longest(
                    tjobs[i::2*nchunks], tjobs[2*nchunks-i-1::2*nchunks])) if x is not None]
        #dojobs.extend(x for x in itertools.chain(*zip(tjobs[i::2*nchunks]+[None], tjobs[2*nchunks-i-1::2*nchunks]+[None])))
        else:
            lj = tjobs[i::2*nchunks] + tjobs[2*nchunks-i-1::2*nchunks]
        dojobs.extend(lj + ([None] * (chunksize - len(lj))))
    sys.stderr.write(f"{len(dojobs)} jobs from {len(jobs)}, {chunksize=}, {nchunks=}\n".format(len(dojobs)))
    return dojobs

parser = argparse.ArgumentParser()
parser.add_argument("directory",help="A single or tree of test directories")
parser.add_argument("-g","--grammar",required=True,help="Enhanced usx.rng RELAXng grammar")
parser.add_argument("-D","--do",default="all",help="Do all*, usx, usfm tests")
parser.add_argument("-S","--start",default="Scripture",help="Starting node for parsing")
parser.add_argument("-m","--marker",action='append',default=[],help='type=mkr,mka,mkb')
parser.add_argument("-s","--size",type=float,default=500000,help="Max test file to run in kB")
parser.add_argument("-M","--match",help="Constrain input files to match regex")
parser.add_argument("--skipfile",help="Logfile name and skip all jobs skipped and passed in that file")
parser.add_argument("-O","--oneerror",action="store_true",help="Bail on a zip after the first faulty sfm file")
parser.add_argument("-T","--timeout",type=int,help="Maximum time to process a file in seconds")
parser.add_argument("-j","--jobs",type=int,default=0,help="Parallel jobs, single=1")
parser.add_argument("-C","--chunks",type=int,help="Size of parallel chunks")
parser.add_argument("-v","--verbose",action="store_true",help="Print things like error messages")
parser.add_argument("-q","--quiet",action="store_true",help="Don't report progress")
parser.add_argument("-l","--logging",default="error",help="Set logging level to usfmxtest.log")
parser.add_argument("--logfile",default="usfmtestdbl.log",help="Out log to file")
parser.add_argument("--logparse",action="store_true",help="Log the parsing as well")
parser.add_argument("-z","--debug",type=int,default=0,help="1=print tree, 2-alt multiproc")
args = parser.parse_args()

if args.logging:
    try:
        loglevel = int(args.logging)
    except ValueError:
        loglevel = getattr(logging, args.logging.upper(), None)
    if isinstance(loglevel, int):
        parms = {'level': loglevel, 'datefmt': '%d/%b/%Y %H:%M:%S',
                 'format': '%(asctime)s.%(msecs)03d %(levelname)s:%(module)s(%(lineno)d) %(message)s'}
        logfh = open(args.logfile, "w", encoding="utf-8")
        parms.update(stream=logfh, filemode="w") #, encoding="utf-8")
        try:
            logging.basicConfig(**parms)
        except FileNotFoundError as e:      # no write access to the log
            print("Exception", e)
    if not args.logparse:
        logging.config.dictConfig({'version': 1, 'disable_existing_loggers': True})
        if args.timeout is None:
            Parser.debug=False
    log = logging.getLogger('usfmtestdbl')

relaxns = "{http://relaxng.org/ns/structure/1.0}"

skips = {}
if args.skipfile and os.path.exists(args.skipfile):
    with open(args.skipfile, encoding="utf-8") as inf:
        for l in inf.readlines():
            m = re.match(r"^(.*): (\S+)(?:\s+\((Passed)\))?", l)
            if m is not None:
                if m.group(2) in ("Passed", "Skipped"):
                    skips[m.group(1)] = m.group(3) or m.group(2)

rdoc = et.parse(args.grammar)
if len(args.marker):
    for s in args.marker:
        t, r = s.split('=')
        mks = re.split(r'[,;\s]\s*', r)
        ty = t.strip()
        e = rdoc.find('./{0}define[@name="{1}.enum"]/{0}choice'.format(relaxns, usxenums[ty]))
        if e is None:
            continue
        for m in mks:
            v = et.Element('value')
            v.text = m.strip()
            e.insert(0, v)
            if ty == 'para':
                partypes[m] = 'Section'

backendsfm = UsfmParserBackend()
sfmproc = UsfmGrammarParser(rdoc, backendsfm)
sfmproc.parseRef(args.start)
newdoc = etree.fromstring(et.tostring(rdoc.getroot(), encoding="utf-8", xml_declaration=True))
usxrng = etree.RelaxNG(etree=newdoc)

jobs = []
skipcount = 0
for dp, dns, fns in os.walk(args.directory):
    for f in fns:
        if not f.lower().endswith(".zip"):
            continue
        if args.match and not re.match(args.match, f, re.I):
            continue
        st = os.stat(os.path.join(dp, f))
        if st.st_size > args.size * 1024:
            continue
        jobname = os.path.join(dp, f)
        if jobname in skips:
            log.info(f"{jobname}: Skipped ({skips[jobname]})")
            skipcount += 1
        else:
            jobs.append((jobname, st.st_size))

if not args.quiet:
    print(f"Skipping {skipcount} jobs")

if args.jobs != 1 and len(jobs) > 1:
    if args.jobs == 0:
        args.jobs = os.cpu_count()
    def doprocone(arg):
        if arg is None:
            return
        return proconezip(arg, sfmproc.curr, log, usxrng, args)
    pool = Pool()
    if args.chunks:
        chunksize = args.chunks
        nchunks = len(jobs) // chunksize
    else:
        nchunks = args.jobs * 4
        chunksize = len(jobs) // nchunks
    dojobs = chunkjobs(jobs, nchunks)
    mapresults = pool.map_async(doprocone, dojobs, chunksize=chunksize)
    results = mapresults.get()
else:
    results = []
    for j in jobs:
        results.append(proconezip(j[0], sfmproc.curr, log, usxrng, args))

failed = 0
passed = 0
skipped = 0
for r in results:
    if r is None or r[1] is None:
        skipped += 1
    elif len(r[1]) == 0:
        passed += 1
    else:
        failed += 1
        if args.verbose:
            print("{}:\n    {}".format(r[0], "    \n".join(r[1])))
total = failed + passed + skipped
print(f"{passed=}, {failed=}, {skipped=}, {total=}")

