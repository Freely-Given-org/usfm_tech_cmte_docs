#!/usr/bin/env -S python3 -u

import argparse, os, sys, logging, re, itertools
from multiprocessing import Pool

try:
    from usfmtc.sfmparser import UsfmParserBackend, parseusfm
except ImportError:
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'lib'))
    from usfmtc.sfmparser import UsfmParserBackend, parseusfm
from usfmtc.parser import NoParseError
from usfmtc.grammar import UsfmGrammarParser, XmlGrammarParser
from usfmtc.usxgrammar import usxenums
from usfmtc.xmlutils import parsexml, writexml, prettyxml
from usfmtc.usx import addesids, etCmp, cell_aligns, cleanup, partypes
import xml.etree.ElementTree as et
from lxml import etree

def proconedir(d, sfmp, relax, args):
    meta = {}
    if os.path.isdir(d):
        doc = et.parse(os.path.join(d, "metadata.xml"))
        for e in doc.getroot():
            meta[e.tag] = e.text
        tags = set((meta.get('tags', "") or "").split())
        if len(args.exclude) and tags & args.exclude and (not len(tags) or not tags & args.include):
            return
    # print(f"{d}: ", end='', flush=True)
    imsg = ""
    xmsg = ""
    try:
        if os.path.isdir(d):
            result = parseusfm(os.path.join(d, "origin.usfm"), sfmp)
        else:
            result = parseusfm(d, sfmp)
    except NoParseError as e:
        imsg = " {} at {}".format(e.msg, e.state.pos).replace("\r", "\\r")
        result = None
    if result is not None:
        passed = True
        if (args.debug & 1) != 0:
            print(result)
        xml = result.asEt()
        addesids(xml)
        cell_aligns(xml)
        cleanup(xml)
        testxml = None
        if not os.path.isdir(d) and args.base and os.path.exists(args.base):
            testxml = parsexml(args.base)
        if os.path.exists(os.path.join(d, "origin.xml")):
            testxml = parsexml(os.path.join(d, "origin.xml"))
        if testxml:
            passed = etCmp(xml, testxml.getroot(), verbose=args.print)
            if not passed:
                xmsg = "USX generated not same as origin.xml!"
        if args.print:
            prettyxml(xml)
            writexml(sys.stdout, xml)
        try:
            etreexml = etree.fromstring(et.tostring(xml, encoding="utf-8", xml_declaration=True))
            if not relax.validate(etreexml):
                xmsg = str(relax.error_log.last_error)
                passed = False
        except Exception as e:
            xmsg = str(e)
            passed=False
    else:
        passed = False
    expected = meta.get('validated', 'pass').lower() == 'pass'
    res = passed == expected
    if not args.quiet:
        print("{}: {} ({} {}){} | {}".format(d, "Passed" if res else "Failed", "==" if res else "!=", "Pass" if expected else "Fail", imsg, xmsg))
    return (res, d, imsg, xmsg)

def chunkjobs(jobs, nchunks, args):
    chunksize = len(jobs) // nchunks
    chunksize += 1 if len(jobs) % nchunks else 0
    tjobs = [j[0] for j in sorted(jobs, key=lambda x:(-x[1], x[0]))]
    dojobs = []
    for i in range(nchunks):
        if args.debug & 2 == 0:
            lj = [x for x in itertools.chain(*itertools.zip_longest(
                    tjobs[i::2*nchunks], tjobs[2*nchunks-i-1::2*nchunks])) if x is not None]
        #dojobs.extend(x for x in itertools.chain(*zip(tjobs[i::2*nchunks]+[None], tjobs[2*nchunks-i-1::2*nchunks]+[None])))
        else:
            lj = tjobs[i::2*nchunks] + tjobs[2*nchunks-i-1::2*nchunks]
        dojobs.extend(lj + ([None] * (chunksize - len(lj))))
    if not args.quiet:
        sys.stderr.write(f"{len(dojobs)} jobs from {len(jobs)}, {chunksize=}, {nchunks=}\n".format(len(dojobs)))
    return dojobs

parser = argparse.ArgumentParser()
parser.add_argument("directory",help="A single or tree of test directories")
parser.add_argument("-g","--grammar",required=True,help="Enhanced usx.rng RELAXng grammar")
parser.add_argument("-b","--base",help="Base USX file to compare against for direct file tests")
parser.add_argument("-S","--start",default="Scripture",help="Starting node for parsing")
parser.add_argument("-P","--print",action="store_true",help="Print generated xml")
parser.add_argument("-q","--quiet",action="store_true",help="Don't output error reports, just stats")
parser.add_argument("-o","--output",help="Output error reports to this file")
parser.add_argument("-m","--marker",action='append',default=[],help='type=mkr,mka,mkb')
parser.add_argument("-j","--jobs",type=int,default=-1,help="Parallel jobs")
parser.add_argument("-x","--exclude",action="append",default=[],help="Exclude test if tag present")
parser.add_argument("-i","--include",action="append",default=[],help="Override excludes to include test if tag present")
parser.add_argument("-s","--size",type=float,default=500000,help="Max test file to run in kB")
parser.add_argument("-l","--logging",help="Set logging level to usfmxtest.log")
parser.add_argument("-z","--debug",type=int,default=0,help="1=print tree, 2-alt multiproc")
args = parser.parse_args()

if "clarify" not in args.include:
    args.exclude.append("clarify")
args.exclude = set(args.exclude)
args.include = set(args.include)

if args.logging:
    try:
        loglevel = int(args.logging)
    except ValueError:
        loglevel = getattr(logging, args.logging.upper(), None)
    if isinstance(loglevel, int):
        parms = {'level': loglevel, 'datefmt': '%d/%b/%Y %H:%M:%S', 'format': '%(asctime)s.%(msecs)03d %(levelname)s:%(module)s(%(lineno)d) %(message)s'}
        logfh = open("usfmxtest.log", "w", encoding="utf-8")
        parms.update(stream=logfh, filemode="w") #, encoding="utf-8")
        try:
            logging.basicConfig(**parms)
        except FileNotFoundError as e:      # no write access to the log
            print("Exception", e)
    log = logging.getLogger('usfmxtest')

jobs = []
if os.path.isdir(args.directory):
    for dp, dns, fns in os.walk(args.directory):
        if 'metadata.xml' in fns:
            st = os.stat(os.path.join(dp, "origin.usfm"))
            if st.st_size > args.size * 1024:
                continue
            jobs.append((dp, st.st_size))
else:
    st = os.stat(args.directory)
    jobs = [(args.directory, st.st_size)]

if len(jobs) == 1:
    args.exclude = []

relaxns = "{http://relaxng.org/ns/structure/1.0}"

rdoc = et.parse(args.grammar)
if len(args.marker):
    for s in args.marker:
        t, r = s.split('=')
        mks = re.split(r'[,;\s]\s*', r)
        ty = t.strip()
        e = rdoc.find('./{0}define[@name="{1}.enum"]/{0}choice'.format(relaxns, usxenums[ty]))
        if e is None:
            print(f"Can't find an enum for {ty}. Tried {usxenums[ty]}")
            continue
        for m in mks:
            v = et.Element(f'{relaxns}value')
            v.text = m.strip()
            e.insert(0, v)
            if ty == 'para':
                partypes[m] = 'Section'

backendsfm = UsfmParserBackend()
sfmproc = UsfmGrammarParser(rdoc, backendsfm)
sfmproc.parseRef(args.start)
newdoc = etree.fromstring(et.tostring(rdoc.getroot(), encoding="utf-8", xml_declaration=True))
usxrng = etree.RelaxNG(etree=newdoc)

if args.jobs > -1 and args.jobs != 1 and len(jobs) > 1:
    if args.jobs == 0:
        args.jobs = os.cpu_count()
    def doprocone(arg):
        if arg is None:
            return
        return proconedir(arg, sfmproc.curr, usxrng, args)
    pool = Pool()
    nchunks = args.jobs * 4
    chunksize = len(jobs) // nchunks
    dojobs = chunkjobs(jobs, nchunks, args)
    poolresults = pool.map_async(doprocone, dojobs, chunksize=chunksize)
    results = list(poolresults.get())
else:
    results = []
    for j in jobs:
        results.append(proconedir(j[0], sfmproc.curr, usxrng, args))

ifailed = 0
xfailed = 0
if args.output:
    outf = open(args.output, "w", encoding="utf-8")
total = 0
for r in results:
    if r is None:
        continue
    if len(r[2]) and not r[0]:
        ifailed += 1
    if len(r[3]) and not r[0]:
        xfailed += 1
    total += 1
    if args.output:
        outf.write(f"{r[1]}: {'Passed' if r[0] else 'Failed'}. {r[2]} {'|xml>'+r[3] if r[3] else ''}\n")
print(f"Total: {total}, usfm_failed: {ifailed}, xml_failed {xfailed}")

